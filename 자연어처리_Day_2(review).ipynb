{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리_Day-2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GWktc8jWFCNQ",
        "oGZQBIpeEIPA",
        "1gb1PqhoIcj1",
        "v9yQdcPsMV6w",
        "Q5eePE37NlWM"
      ],
      "authorship_tag": "ABX9TyPkkQUuTAtwka0guujpRKNI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQahXw6gu0e1",
        "outputId": "ee3a207f-7f1b-4948-cd4d-ef253a6391c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정규표현식"
      ],
      "metadata": {
        "id": "GWktc8jWFCNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1x3ZlT2B7D1A"
      },
      "outputs": [],
      "source": [
        "import re "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'I was wondering if anyone out there could enlighten me on this car'"
      ],
      "metadata": {
        "id": "4dXp3n7t7lbD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ab = re.compile(\"ab..\") # ab로 시작되는 4글자 를 찾아달라/문자 뒤에 .의 갯수만큼 글자 추출"
      ],
      "metadata": {
        "id": "3HpDS_Bp8AvF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ab.search(\"kkkkkkkkkkkabcccccccccc\") #search는 중간에 있든 어디있든 위치에 상관없음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5dPWgyG8nt6",
        "outputId": "cd252792-1697-4a83-ba39-97d525d9560a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(11, 15), match='abcc'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.split() #빈칸은 \" \"와 같음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJSfUWOi8u06",
        "outputId": "43800833-c9c8-4578-fb56-5cd7e9b1f0cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'was',\n",
              " 'wondering',\n",
              " 'if',\n",
              " 'anyone',\n",
              " 'out',\n",
              " 'there',\n",
              " 'could',\n",
              " 'enlighten',\n",
              " 'me',\n",
              " 'on',\n",
              " 'this',\n",
              " 'car']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ab.match(\"kdabc\")) # match는 맨앞에서 부터 시작해야함\n",
        "print(ab.match(\"abckd\")) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3d4yfvE8zvo",
        "outputId": "58396616-15bf-4214-c680-33c46fe30f4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "<re.Match object; span=(0, 4), match='abck'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"aa\\naa\")\n",
        "print(r\"aa\\naa\") # r을 문자열 앞에 쓰면 \\의 특수기능을 잃어버림(파이썬은 특수하게 r을 사용하면 백슬래쉬를 1개만 써도 두개를 쓴 것과 같은 효과를 갖는다.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "317xfZRB7Wb_",
        "outputId": "05a52ed5-c9af-4108-8baf-f4aeac7ecd4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aa\n",
            "aa\n",
            "aa\\naa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shortword = re.compile(r\"\\W*\\b\\w{1,2}\\b\")"
      ],
      "metadata": {
        "id": "GXoWtVRo9a6Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(shortword.sub(\" \",text)) #.sub(repl,string) / repl:Read Eval Print Loop\n",
        "# text에서 shortword에 해당하는 단어들을 빈칸으로 구분하며 나열"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSMsEq3o9tVx",
        "outputId": "c79e6bd7-c3e2-4660-ad08-ebbe6402d86b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  was wondering  anyone out there could enlighten   this car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규표현식 실습\n",
        "import re\n",
        "r = re.compile(\"a.c\") # a와c사이 한글자\n",
        "r.search(\"kkk\")\n",
        "r.search(\"abc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRQqktkG2JWA",
        "outputId": "44c0824b-96d7-4a5b-812f-5ade3d9aa27a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab?c\") # ?앞의 글자가 있을수도 없을수도 있음\n",
        "r.search(\"abbc\")\n",
        "r.search(\"abc\")\n",
        "r.search(\"ac\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X-_TpVc2f17",
        "outputId": "2fda78a3-eca2-45c4-a36e-f5b9a49d7999"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ac'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab*c\") # *앞의 글자가 없을 수도 여러개 있을 수도 있음, 단 뒤에 글자(c)는 반드시 있어야함\n",
        "r.search(\"a\")\n",
        "r.search(\"ac\")\n",
        "r.search(\"abc\")\n",
        "r.search(\"abbbbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5_LZcLN3Kla",
        "outputId": "95311008-b264-46ca-d04a-0a173b7d2128"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 6), match='abbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab+c\") # +앞의 글자가 여러개 있음, 단 적어도 1개는 무조건 있어야함\n",
        "r.search(\"ac\")\n",
        "r.search(\"abc\")\n",
        "r.search(\"abbbbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7OUofzr4L5X",
        "outputId": "64b73d13-d41d-4705-e4aa-fc1f0ebb0cfb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 6), match='abbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"^ab\") # 해당 글자앞에 아무것도 없어야함(ab로 시작하는 문장에서 ab를 추출)\n",
        "r.search(\"bbc\")\n",
        "r.search(\"zab\")\n",
        "r.search(\"abzzzzz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zZQfFBk4rqd",
        "outputId": "621abb5c-ae57-40e0-b727-00b26a363263"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ab'>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{2}c\") # {n}앞의 글자가 n개만 있어야함\n",
        "r.search(\"ac\")\n",
        "r.search(\"abc\")\n",
        "r.search(\"abbbbbc\")\n",
        "r.search(\"abbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6mccrLO5M5m",
        "outputId": "b152e4b7-3d72-4001-f9fd-ee41e4a9d1b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 4), match='abbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{2,8}c\") # {a,b}앞의 글자가 a~b개만 있어야함\n",
        "r.search(\"ac\")\n",
        "r.search(\"abc\")\n",
        "r.search(\"abbbbbbbbbc\")\n",
        "r.search(\"abbc\")\n",
        "r.search(\"abbbbbbbbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L9VaLKw51fp",
        "outputId": "ee03af8f-c8e9-48ff-da2f-4376c7265498"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 10), match='abbbbbbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[abc]\") # 가장 먼저 나오는 a혹은b혹은c\n",
        "r.search(\"zzz\")\n",
        "r.search(\"a\")\n",
        "r.search(\"aaaaaaaa\")\n",
        "r.search(\"baac\")\n",
        "r.search(\"ab\") # 제일 먼저 나오는 한글자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s57oyxV6JgQ",
        "outputId": "a39d1345-0412-486b-bcbd-2de41fc5ace3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='a'>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[a-c]\") # a부터c까지"
      ],
      "metadata": {
        "id": "6tjuxgWJ6vp8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[^abc]\") # abc를 제외한 나머지 문자로 이루어진 텍스트 1개를 추출\n",
        "r.search(\"a\")\n",
        "r.search(\"ab\")\n",
        "r.search(\"b\")\n",
        "r.search(\"d\")\n",
        "r.search(\"ki\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLBaejqc7PVF",
        "outputId": "a8e999f3-9215-412a-f953-e992c8d4328f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='k'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab.\")\n",
        "r.match(\"nabc\")\n",
        "r.match(\"nabc\")\n",
        "r.match(\"abcn\") #match는 맨앞에서 시작해야지만 매칭이 됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoT4nQEq78BX",
        "outputId": "641b99c7-4745-46d0-b361-c4133473e002"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"이름 : 김철수\n",
        "전화번호 : 010 - 1234 - 1234\n",
        "나이 : 30\n",
        "성별 : 남\"\"\"\n",
        "re.findall(\"\\d+\",text) # 숫자는 \\d/ 숫자 뭉치 \\d+\n",
        "# re.findall(\"\\d+\",\"자1연2어3처4리5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LqknL9W8UkM",
        "outputId": "6dd80197-462d-43f2-ccbc-2c01f4cc445b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['010', '1234', '1234', '30']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Regular expression : A regular expression, regex or regexp[1](sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
        "p_text = re.sub(\"[^a-zA-Z]\",\" \",text) # 알파벳이 아닌 것들은 공백으로 치환\n",
        "# re.sub(pattern, repl, string)\n",
        "print(p_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cECTJ0MZ9cgi",
        "outputId": "5f300aa5-cace-4818-8382-be0375f1fa18"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular expression   A regular expression  regex or regexp    sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##정규표현식 전처리 실습"
      ],
      "metadata": {
        "id": "oGZQBIpeEIPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"100 John     PROF\n",
        "101 James     STUD\n",
        "102 Mac     STUD\"\"\"\n",
        "# 공백 기준 분리\n",
        "re.split(\"\\s+\", text) # \\s는 스페이스를 나타내고, \\s+는 여러개의 스페이스를 나타냄\n",
        "# 텍스트를 공백으로 나눔"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYqXAvd1ELkH",
        "outputId": "d934921f-156f-43fb-91a2-f090301dd704"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자(뭉치)만 추출\n",
        "re.findall(\"\\d+\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVIS8bVmFMe1",
        "outputId": "b355d07b-566b-4eea-9d54-1da89d608449"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', '101', '102']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트가 대문자인 행 추출\n",
        "re.findall(\"[A-Z]{4}\", text) # 대문자가 연속해서 4번 나오는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMGGBbBFFMbZ",
        "outputId": "2de5d46b-3dfc-47dd-b115-47eeadc3d18a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROF', 'STUD', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 처음만 대문자인 단어 추출\n",
        "re.findall(\"[A-Z][a-z]+\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4HOdtrWF_ag",
        "outputId": "688245a1-e5b0-4578-8336-7ec16cf65dcb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John', 'James', 'Mac']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "text = \"Don't be fooled by the dark sounding name, Mr.Jone's Orphanage is as cheery as cheery goes for a pastry shop\"\n",
        "\n",
        "# 특수문자 혹은 공백 기준 단어 및 숫자 분리\n",
        "tokenizer1 = RegexpTokenizer(\"[\\w]+\") # 문자 또는 숫자가 한개 이상, .이나 '와 같은 특수 문자를 기준으로도 분리가 되는 것이 확인 가능\n",
        "print(tokenizer1.tokenize(text))\n",
        "\n",
        "# 공백 기준 단어 분리\n",
        "tokenizer2 = RegexpTokenizer(\"\\s+\", gaps = True) \n",
        "print(tokenizer2.tokenize(text))\n",
        "\n",
        "tokenizer3 = RegexpTokenizer(\"\\s+\") #토큰화 시키는 기준점을 나타냄\n",
        "print(tokenizer3.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpHAFekRGgjx",
        "outputId": "96cbc166-b6e9-43bf-f616-37f21a2259f3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', \"Mr.Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 레이블 인코딩"
      ],
      "metadata": {
        "id": "1gb1PqhoIcj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "raw_text = \"A barber is a person? a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy, the barber went up a huge mountain.\""
      ],
      "metadata": {
        "id": "WB9ARK83IfuQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(raw_text) # 마침표(? ! .)를 기준으로 분리됨\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uMWdrj_I6mI",
        "outputId": "e3965a54-2a7e-42b2-fdc5-2e86a082c03e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A barber is a person?', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy, the barber went up a huge mountain.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "preprocessed_sentences = []\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "for sentence in sentences:\n",
        "  tokenized_sentence = word_tokenize(sentence)\n",
        "  result = []\n",
        "\n",
        "  for word in tokenized_sentence:\n",
        "    word = word.lower()\n",
        "    if word not in stop_words:\n",
        "      if len(word) > 2:\n",
        "        result.append(word)\n",
        "        if word not in vocab:\n",
        "          vocab[word] = 0\n",
        "        vocab[word] += 1\n",
        "\n",
        "  preprocessed_sentences.append(result)\n",
        "print(vocab)\n",
        "print(vocab[\"barber\"])\n",
        "svocab = sorted(vocab.items(), key = lambda item : item[1], reverse = True ) # 빈도수가 높은 순으로 정렬\n",
        "print(svocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7tVo5WsJVBW",
        "outputId": "e57b95d8-1e3b-41c3-a3e2-d41bfa0b5397"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n",
            "8\n",
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 표제어 추출"
      ],
      "metadata": {
        "id": "tfLLiNmZFKAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization 표제어 추출(사전형 단어 찾기)\\\n",
        "am/are/is -> be\\\n",
        "단어는 언간+접사\\\n",
        "dogs -> dog + s\n"
      ],
      "metadata": {
        "id": "e2p1ziJpBPR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "wnLZE98d9zmE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "PzuI-98dC2cx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ceWjEKDsl-",
        "outputId": "62057a74-fb0c-47c8-8b09-b788d38ef717"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"have\", \"going\", \"love\", \"lives\", \"dies\", \"watched\", \"has\"]\n",
        "print(\"표제어 추출 전 :\", words)\n",
        "print(\"표제어 추출 후 :\", [lemmatizer.lemmatize(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-XURT1BC954",
        "outputId": "6e9c0e21-4335-4951-be55-53f1a64964b6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표제어 추출 전 : ['have', 'going', 'love', 'lives', 'dies', 'watched', 'has']\n",
            "표제어 추출 후 : ['have', 'going', 'love', 'life', 'dy', 'watched', 'ha']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"dies\", \"v\") # \"v\"는 동사형\n",
        "# 품사를 입력해주지 않으면 어색해지는 경우가 종종생김"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yaIdaRwNDfky",
        "outputId": "e5857e66-e563-430f-c5ee-876f83520b5c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'die'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"watched\", \"v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nCqnQ49QE3_l",
        "outputId": "f33278f3-3b28-45aa-a5ff-958d5c5dc9ae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'watch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"has\", \"v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rPfTq8QGFZB9",
        "outputId": "f8f34152-c6fd-4c64-955e-a669dcca627b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "stemming 어간 추출\\\n",
        "Porter Algorithm\\\n",
        "Lancaster Stemmer Algorithm"
      ],
      "metadata": {
        "id": "IWHcEpAhGynf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This was not the map we found in Bill Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\""
      ],
      "metadata": {
        "id": "hxAyDujmGx9m"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer # 어간과 어미를 분리하는 클래스\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "p_stemmer = PorterStemmer()\n",
        "l_stemmer = LancasterStemmer()\n",
        "\n",
        "tokenized_sentence = word_tokenize(sentence)"
      ],
      "metadata": {
        "id": "JUpHSJCSIIin"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSxc_5b1Iosn",
        "outputId": "ab7d8dac-49fb-499f-c57d-fa36b1c0f326"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'was',\n",
              " 'not',\n",
              " 'the',\n",
              " 'map',\n",
              " 'we',\n",
              " 'found',\n",
              " 'in',\n",
              " 'Bill',\n",
              " 'Bones',\n",
              " \"'s\",\n",
              " 'chest',\n",
              " ',',\n",
              " 'but',\n",
              " 'an',\n",
              " 'accurate',\n",
              " 'copy',\n",
              " ',',\n",
              " 'complete',\n",
              " 'in',\n",
              " 'all',\n",
              " 'things',\n",
              " '--',\n",
              " 'names',\n",
              " 'and',\n",
              " 'heights',\n",
              " 'and',\n",
              " 'soundings',\n",
              " '--',\n",
              " 'with',\n",
              " 'the',\n",
              " 'single',\n",
              " 'exception',\n",
              " 'of',\n",
              " 'the',\n",
              " 'red',\n",
              " 'crosses',\n",
              " 'and',\n",
              " 'the',\n",
              " 'written',\n",
              " 'notes',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([p_stemmer.stem(word) for word in tokenized_sentence])\n",
        "print([l_stemmer.stem(word) for word in tokenized_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ECd3xGJII0",
        "outputId": "04b73f61-c945-4422-aa89-cfc8a0506ca1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'bill', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n",
            "['thi', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'bil', 'bon', \"'s\", 'chest', ',', 'but', 'an', 'acc', 'cop', ',', 'complet', 'in', 'al', 'thing', '--', 'nam', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'exceiv', 'of', 'the', 'red', 'cross', 'and', 'the', 'writ', 'not', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 한국어 어간 비교\n",
        "5언 9품사\n",
        "언 : 품사\\\n",
        "체언 : 명사, 대명사, 수사\\\n",
        "수식언 : 관형사, 부사\\\n",
        "관계언 : 조사\\\n",
        "독립언 : 감탄사\\\n",
        "용언 : 동사, 형용사\\\n",
        "규칙 활용\n"
      ],
      "metadata": {
        "id": "v9yQdcPsMV6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 불용어\n",
        "Stopword 불용어\\\n",
        "큰 의미가 없는 단어 토큰을 제거하는 작업\\\n",
        "I, my, me, over, 조사, 접미사 등\\\n",
        "직접정의\\\n",
        "영어 및 한국어 불용어 실습"
      ],
      "metadata": {
        "id": "Q5eePE37NlWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK0UvM6lnFKQ",
        "outputId": "001da838-a677-48ee-cc1c-ca9dd1ffb8c7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords # corpus:말뭉치\n",
        "from nltk.tokenize import word_tokenize # 토큰화\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "stop_words_list = stopwords.words(\"english\")\n",
        "print(len(stop_words_list))\n",
        "print(stop_words_list[:10])"
      ],
      "metadata": {
        "id": "GLZ6ucCUJob_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb64ce8-72a0-4a7e-984f-8d67f45fbc6b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 제거\n",
        "example = \"Family is not an important thing. It's everything.\"\n",
        "stop_words = set(stopwords.words(\"english\")) # 중복되는 요소가 있을 수도 있으니 set\n",
        "word_tokens = word_tokenize(example)"
      ],
      "metadata": {
        "id": "6Z0t0xe6m2Mb"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOgG7U8Fp0aQ",
        "outputId": "085f43ef-d348-43a3-b8a6-d125f1475006"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d', 'our', 'in', 'very', 'hasn', \"you've\", 've', 'under', 'how', 'once', 'the', 'should', 'because', \"weren't\", \"doesn't\", 'for', 'to', 'being', 'that', 'has', \"needn't\", \"mustn't\", \"that'll\", 'by', 'mustn', 'who', \"you'd\", 'now', 'haven', 'are', 'will', 'wouldn', \"she's\", \"couldn't\", 'ours', 'them', 'such', 'mightn', 'as', 'himself', 'they', 'there', 'did', \"you're\", 'll', 'she', 'an', 'same', 'between', 'having', 'shan', \"wouldn't\", 'm', 'down', 'own', 'about', 'your', 'any', 'this', \"haven't\", 'here', 'ain', 'a', 'his', 'we', 'were', 'of', \"won't\", 'more', 'with', 'their', 'me', \"it's\", 'o', 'doing', 'few', 'below', \"didn't\", 'myself', 'needn', 'on', 'be', 'hers', 'does', 'where', \"isn't\", 'was', 'too', 'from', 'its', 'didn', \"don't\", 'which', 'have', 'and', 'theirs', \"you'll\", 'most', 'during', 'had', 'when', 'my', 'herself', 'at', 's', 'isn', 'what', 'why', 'been', 'can', 'doesn', \"hasn't\", 'won', 'up', \"aren't\", 'ourselves', 'nor', 'her', 'again', 'these', 'so', 't', 'it', 'not', 'shouldn', 'while', 'after', \"shouldn't\", \"hadn't\", 'but', 'ma', 'until', 'am', 'some', 'y', 'yourself', 'all', \"should've\", 'those', 'him', 'or', 're', 'yours', 'if', 'above', 'then', 'whom', 'out', 'itself', 'don', 'hadn', 'yourselves', \"mightn't\", 'wasn', 'only', 'you', 'than', 'couldn', 'against', 'he', 'themselves', 'both', 'each', 'just', 'through', 'do', 'off', 'other', 'is', \"wasn't\", 'further', 'into', 'i', \"shan't\", 'aren', 'over', 'weren', 'no', 'before'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in stop_words:\n",
        "  if word in word_tokens: # word_tokens에 불용어가 있다면 그 불용어 제거\n",
        "    word_tokens.remove(word)\n",
        "# word_tokens.remove(word) for word in stop_words if word in word_tokens\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t-IUK5RoxdB",
        "outputId": "9b61197f-4c48-4930-c96a-d166060c6af7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 불용어 제거\n",
        "okt = Okt() # Open Korean Text\n",
        "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\"\n",
        "stop_words = set(stop_words.split(\" \"))\n",
        "word_tokens = okt.morphs(example)\n",
        "result = [word for word in word_tokens if not word in stop_words] #불용어 리스트에 그 단어가 없다면 리스트에 입력\n",
        "print(\"불용어 제거 전 :\",word_tokens)\n",
        "print(\"불용어 제거 후 :\",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_6p76YBpfyg",
        "outputId": "d73665d0-8611-4523-b561-c7f2dd2c5611"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전 : ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
            "불용어 제거 후 : ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 사전.txt 파일을 가지고 있는 경우\n"
      ],
      "metadata": {
        "id": "h8qFwa6NtdH8"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IHGuYcebJZhq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}